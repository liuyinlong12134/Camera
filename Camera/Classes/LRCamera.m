 //
//  LRCamera.m
//  LRGPUimage
//
//  Created by liurui on 2016/8/10.
//  Copyright Â© 2016å¹´ liurui. All rights reserved.
//

#import "LRCamera.h"

@interface LRCamera ()
<
AVCaptureVideoDataOutputSampleBufferDelegate,
AVCaptureAudioDataOutputSampleBufferDelegate
>
@property(nonatomic,strong) AVCaptureSession *session;
@property(nonatomic,strong) AVCaptureVideoDataOutput *videoOutput;

@end

@implementation LRCamera
+ (instancetype)cameraWithSessionPreset:(NSString *)sessionPreset postion:(AVCaptureDevicePosition)postion
{
    LRCamera * camera = [[LRCamera alloc]init];
    //åˆ›å»ºæ•æ‰ä¼šè¯
    [camera setupSession:sessionPreset];
    //æ·»åŠ æ•è·è§†é¢‘æ•°æ®
    [camera setupVideo:postion];
    //æ·»åŠ æ•è·éŸ³é¢‘æ•°æ®ã€
    //éŸ³é¢‘åº•å±‚æ ¼å¼æ˜¯PCM
    return camera;
}

- (instancetype)init
{
    if(self = [super init])
    {
        
        _VideoOrientation = AVCaptureVideoOrientationPortrait;
        _frameRaw = 15;
        _isVedioDataRGB = NO;
    }
    return self;
}
- (void)setIsCaptureAudioData:(BOOL)isCaptureAudioData
{
    _isCaptureAudioData = isCaptureAudioData;
    
    if(_isCaptureAudioData == YES)
    {
            [self setupAudio];
    }
    
}

-(void)setupSession:(NSString *)sessionPreset
{
    AVCaptureSession *session = [[AVCaptureSession alloc]init];
    _session = session;
    
    if(sessionPreset.length == 0)
    {
        sessionPreset = AVCaptureSessionPresetHigh;
    }
    
    session.sessionPreset = sessionPreset;
}
- (void) setupVideo:(AVCaptureDevicePosition)postion
{
    //è·å–å‰ç½®æ‘„åƒå¤´
    
    //æ´»å–ç…§ç›¸æœº
    AVCaptureDevice * videoDevice = [self videoDeviceWithposition:postion];
    NSLog(@"%@",videoDevice);
    //æ•è·è§†é¢‘=ã€‹è§†é¢‘è¾“å…¥ è§†é¢‘è¾“å‡º
    //åˆ›å»ºè§†é¢‘è¾“å…¥
    //æŒ‡å®šä¸€ä¸ªè®¾å¤‡åˆ›å»ºå¯¹åº”çš„è®¾å¤‡è¾“å…¥å¯¹è±¡
    //    AVCaptureInput *av = [[AVCaptureInput alloc]init];//åŸºç¡€ç±»
    AVCaptureDeviceInput * videoInput = [AVCaptureDeviceInput deviceInputWithDevice:videoDevice error:nil];
    //æ•è·è§†é¢‘æ•°æ®
    
    //åˆ›å»ºè§†é¢‘è¾“å‡º,è·å–é‡‡é›†è§†é¢‘æ•°æ®ä¸å†™æˆæ–‡ä»¶
    AVCaptureVideoDataOutput *videoOutput = [self setupVideoOutput];
    self.videoOutput = videoOutput;

    //ç»™å›è¯æ·»åŠ è§†é¢‘è¾“å…¥ï¼ˆè¾“å‡ºï¼‰
    if([_session canAddInput:videoInput])
    {
        [_session addInput:videoInput];
    }
    if([_session canAddOutput:videoOutput])
    {
        [_session addOutput:videoOutput];
    }
    
    AVCaptureConnection *videoconnection =  [videoOutput connectionWithMediaType:AVMediaTypeVideo];
    videoconnection.videoMirrored = NO;//é•œåƒ
    //ä¸‹é¢æ˜¯ç«–å±ğŸ‘‡    ç³»ç»Ÿç»™çš„æ•°æ®å°±æ˜¯ç«–å±æ•°æ®
    videoconnection.videoOrientation = AVCaptureVideoOrientationPortraitUpsideDown;

}
-(void)setupAudio
{
    //è·å–éŸ³é¢‘è®¾å¤‡
    AVCaptureDevice * AudioDeV = [AVCaptureDevice defaultDeviceWithMediaType:AVMediaTypeAudio];
    //è½¬æ¢æˆéŸ³é¢‘è¾“å…¥
    AVCaptureDeviceInput * aUdioinput =[[AVCaptureDeviceInput alloc]initWithDevice:AudioDeV error:nil];
    //éŸ³é¢‘è¾“å‡º
    AVCaptureAudioDataOutput *aUdiooutput = [[AVCaptureAudioDataOutput alloc]init];
    dispatch_queue_t videoQueue = dispatch_queue_create("AudioQueue",DISPATCH_QUEUE_SERIAL);
    [aUdiooutput setSampleBufferDelegate:self queue:videoQueue];
    
    if ([_session canAddInput:aUdioinput]) {
        [_session addInput:aUdioinput];
    }
    if ([_session canAddOutput:aUdiooutput]) {
        [_session addOutput:aUdiooutput];
    }
    
    
}
//æŒ‡å®šä¸€ä¸ªæ‘„åƒå¤´æ–¹å‘ï¼Œå›å»å¯¹åº”æ‘„åƒè®¾å¤‡
-(AVCaptureDevice *)videoDeviceWithposition:(AVCaptureDevicePosition)position
{
    NSArray *videoDevices = [AVCaptureDevice devicesWithMediaType:AVMediaTypeVideo];
    
    for(AVCaptureDevice *device in videoDevices)
    {
        if (device.position == position) {
            return device;
        }
        
    }
    return nil;
    
}
- (AVCaptureVideoDataOutput *)setupVideoOutput
{
    // åˆ›å»ºè§†é¢‘è¾“å‡º
    // è·å–é‡‡é›†è§†é¢‘æ•°æ®,å¹¶ä¸æ˜¯å†™æˆæ–‡ä»¶
    AVCaptureVideoDataOutput *videoOutput = [[AVCaptureVideoDataOutput alloc] init];
    
    //å‰ä¸ºç¬¬å‡ å¸§ åä¸ºæ¯ç§’å¤šå°‘å¸§
    videoOutput.minFrameDuration = CMTimeMake(1,_frameRaw);
    //   minFrameDuration :å¸§ç‡ï¼ˆæœ€å°å¸§ç‡ï¼‰(å¤ªå°ä¸ä¸€å®šæˆåŠŸ)
    
    
    //   videoSettingsï¼šè®¾ç½®è§†é¢‘æ ¼å¼ï¼ˆYUVã€RGBï¼‰ï¼ˆè‹¹æœå¼€å‘ä¸­æä¾›çš„æ¸²æŸ“åªæ”¯æŒRGBï¼ˆæœ€å¥½ç”¨RGBï¼‰ï¼‰
    // ä½†æ˜¯ç›´æ’­ä¸­å¤§å¤šç”¨YUV ï¼ˆæµåª’ä½“å¸¸ç”¨ç¼–ç æ–¹å¼ï¼‰(å°†YUVçŸ©é˜µè£…æ¢æˆRGBï¼Œç¾å›¾RGB)
    NSNumber *dataFm = nil;
    if(_isVedioDataRGB)
    {
        dataFm =@(kCVPixelFormatType_32BGRA);
    }else
    {
        dataFm =@(kCVPixelFormatType_420YpCbCr8BiPlanarFullRange);
    }
    
    videoOutput.videoSettings = @{(NSString *)kCVPixelBufferPixelFormatTypeKey:dataFm};
    //   alwaysDiscardsLateVideoFrames å»¶è¿Ÿæ—¶å€™æ˜¯å¦ä¸¢å¸§
    videoOutput.alwaysDiscardsLateVideoFrames = YES;
    //é€šè¿‡ä»£ç†è·å–é‡‡é›†æ•°æ®  é˜Ÿåˆ—è¦åŒæ­¥é˜Ÿåˆ— å› ä¸ºè·å–å›¾åƒå¸§æœ‰é¡ºåº
    //åˆ›å»ºåŒæ­¥é˜Ÿåˆ—
    dispatch_queue_t videoQueue = dispatch_queue_create("videoQueue",DISPATCH_QUEUE_SERIAL);
    [videoOutput setSampleBufferDelegate:self queue:videoQueue];
    return videoOutput;
    
}

#pragma mark - AVCaptureVideoDataOutputSampleBufferDelegate(ä»£ç†æ–¹æ³•)

- (void)captureOutput:(AVCaptureOutput *)captureOutput didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection
{
    if(_videoOutput == captureOutput)//è§†é¢‘
    {
        if (_CaptureVidoesampleBufferBlock)
        {
             _CaptureVidoesampleBufferBlock(sampleBuffer);
        }
    }else
    {
        if (_CaptureAudiosampleBufferBlock)//éŸ³é¢‘
        {
            _CaptureAudiosampleBufferBlock(sampleBuffer);
        }
     }
}
- (void)startCapture
{
    [_session startRunning];
}
@end



/*
 ç»éªŒï¼šåªè¦è‹¹æœåŸç”Ÿç±»å±æ€§å¾ˆå°‘ä¸€èˆ¬éƒ½æ˜¯ï¼ˆåŸºç±»ï¼‰ï¼›éœ€è¦å¯»æ‰¾å­ç±»ï¼ˆæ ¹æ®åŠŸèƒ½ï¼‰ï¼›
 AVCaptureDevice(æ‘„åƒå¤´éº¦å…‹é£)(è®¾å¤‡)ã€‚ï¼ˆæœ¬è´¨ä¸èƒ½è¾“å‡ºä¸œè¥¿ï¼‰
 AVCaptureInput     ç®¡ç†æ•°æ®é‡‡é›†
 AVCaptureOutput g ç®¡ç†è®¾å¤‡æ•°æ®è¾“å‡ºï¼ˆæ–‡ä»¶ã€å›¾ç‰‡ï¼‰
 AVCaptureSessionï¼šç®¡ç†è¾“å…¥åˆ°è¾“å‡ºæ•°æ®
 AVCaptureSessionï¼šç»™å®šä¸€ä¸ªè¾“å…¥è¾“å‡ºè®¾å¤‡å°±ä¼šåœ¨è¾“å…¥å’Œè¾“å‡ºè®¾å¤‡ä¸­ç®€å†é“¾æ¥AVCaptureCnncion
 AVCaptureVideoPreviewLayer:å±•ç¤ºé‡‡é›†æ•°æ®ã€‚
 AVCaptureVideoDataOutput:è·å–è®¾å¤‡è¾“å‡ºæ•°æ®ï¼ˆæ‘„åƒå¤´ï¼‰
 AVCaptureAudioDataOutput éŸ³é¢‘æ•°æ®
 é‡‡é›†è§†é¢‘ï¼šâ€”â€”æ‘„åƒå¤´AV
 
 é‡‡é›†éŸ³é¢‘ï¼š--------éº¦å…‹é£
 //å¼€å§‹æ•è·ï¼Œä¼šæŠŠè¾“å…¥è®¾å¤‡æ•°æ®ä¼ å…¥åˆ°è¾“å‡ºè®¾å¤‡ä¸Š
 -ï¼ˆvoidï¼‰startRuning;
 
 //é‡‡é›†åˆ°æ•°æ®åè¿›è¡Œâ€”â€”ã€‹æ»¤é•œå¤„ç†â€”â€”ã€‹æ˜¾ç¤º
 
 */



//*********************************åŸå§‹å„ä¸ªæ•°æ®ä»£è¡¨æ„æ€**************************************
//è·å–æ¯ä¸€å¸§æ’­æ”¾çš„æ—¶é•¿
// CMSampleBufferGetDuration(<#CMSampleBufferRef  _Nonnull sbuf#>)è®¡ç®—è§†é¢‘æ—¶é•¿å±æ€§
//CMBlockBufferRef:æŠŠå›¾ç‰‡å‹ç¼©åçš„æ•°æ®ï¼›
//CMSampleBufferCreateå‹ç¼©ä¹‹åè§£ç æ˜¾ç¤ºï¼›
//è·å–å›¾ç‰‡è®¯æ¯
//    CMSampleBufferGetImageBuffer(<#CMSampleBufferRef  _Nonnull sbuf#>);
//è·å–å¸§çš„å°ºå¯¸
//    CMSampleBufferGetSampleSize(<#CMSampleBufferRef  _Nonnull sbuf#>, <#CMItemIndex sampleIndex#>)
//VideoToolbox:ç¡¬ç¼–ç å¸§æ•°ç»è¿‡H.264å‹ç¼©  NALï¼ˆPTS,DTS,I,P,Bï¼‰
//ç¼–ç 
//PTS:å±•ç¤ºæ—¶é—´
//    CMSampleBufferGetPresentationTimeStamp(<#CMSampleBufferRef  _Nonnull sbuf#>)
//DTSå¸§çš„å‹ç¼©æ—¶é—´

//    CMSampleBufferGetDecodeTimeStamp(<#CMSampleBufferRef  _Nonnull sbuf#>)
//è·å–å¸§æ ¼å¼,é€šè¿‡å…¶è·å–PTSï¼ŒDTS
//    CMSampleBufferGetFormatDescription(<#CMSampleBufferRef  _Nonnull sbuf#>)




/*CPUå¤„ç†**************************æ»¤é•œä¸æ¸²æŸ“*********************************************
 //ciimagç›´æ¥å¯ä»¥è·å–é‚£äº›æ»¤é•œå¯ä»¥å¤„ç†å›¾ç‰‡
 NSArray *filters = [cimg autoAdjustmentFilters];
 for (CIFilter *filter in filters) {
 NSLog(@"%@",filter.name);
 }
 NSLog(@"%@",[filters.firstObject class]);
 
 //å…ˆè¦è· å–æ»¤é•œåç§°é€šè¿‡åç§°æ‰¾åˆ°å¯¹åº”çš„å¯¹è±¡
 //   NSArray *filterNames =   [CIFilter filterNamesInCategory:kCICategoryVideo];
 //    //åˆ›å»ºæ»¤é•œ
 //    //CIFilteré€šè¿‡KVCè®¾ç½®
 //    //attributesï¼šè·å–å±æ€§å¯¹åº”çš„ç±»å‹
 //    //inputKeys:è·å–CIFilterçš„é‚£äº›å±æ€§å¯ä»¥è®¾ç½®
 CIFilter *filter =  [CIFilter filterWithName:@"CIPhotoEffectTransfer"];
 //    [filter setValue:@4 forKey:@"inputEV"];
 [filter setValue:cimg forKey:@"inputImage"];
 cimg =  filter.outputImage;
 UIImage * image = [UIImage imageWithCIImage:cimg];
 dispatch_sync(dispatch_get_main_queue(), ^{
 self.imageView.image = image;
 });
 */






/***********************åŸå§‹å¤„ç†æ³•************************************
 -(void)prosesssampleBuffer:(CMSampleBufferRef)sampleBuffer
 {
 @autoreleasepool {
 
 //å…¶å®è¿™ä¸ªæ–¹æ³•ç”¨æ¥GPUç”¨çš„æ›´é«˜è¿˜æ˜¯ç›´æ¥è½¬ciimageå¥½äº²æµ‹
 
 //OpenGL
 //EAGLContext:ä¸Šä¸‹æ–‡åº•å±‚æ˜¯é€šè¿‡openGLæ¸²æŸ“çš„
 //è·å–åŸå›¾ç‰‡ä¿¡æ¯
 CVImageBufferRef imageref =  CMSampleBufferGetImageBuffer(sampleBuffer);
 //è·å–CIimage
 CIImage * cimg = [CIImage imageWithCVImageBuffer:imageref];
 //    CIContext
 //åˆ›å»ºopenglä¸Šä¸‹æ–‡
 EAGLContext *openGLcontext = [[EAGLContext alloc]initWithAPI:kEAGLRenderingAPIOpenGLES2];
 //åˆ›å»ºcoreImageä¸Šä¸‹æ–‡
 CIContext *context =   [CIContext contextWithEAGLContext:openGLcontext];
 //ciimage extentå¯ä»¥ç›´æ¥å»é™¤bounds æ‹¿åˆ°äº†é€šè¿‡OPenGLæ¸²æŸ“çš„å›¾ç‰‡
 CGImageRef  imgref =   [context createCGImage:cimg fromRect:cimg.extent];
 UIImage * image =  [UIImage imageWithCGImage:imgref];
 dispatch_sync(dispatch_get_main_queue(), ^{
 self.imageView.image = image;
 });
 //*********************ä¸ç®¡ç†å¯èƒ½ç›´æ¥çˆ†æ‰
 //    CGImageRelease(imgref);
 }
 }
 */







/**************ä»£ç†æ–¹æ³•ä¸€äº›å°å¤„ç†å’Œä¸€äº›å°ä¸œè¥¿**************************
 //åè®®
 //è·å–ä¸€é’ˆå°±ä¼šè°ƒç”¨
 //CVImageBufferRef = CVPixelBufferRefå›¾ç‰‡çš„ç¼“å­˜æ•°æ®
 //é‡‡é›†åˆ°æ•°æ®åè¿›è¡Œâ€”â€”ã€‹æ»¤é•œå¤„ç†ï¼ˆCIFIlterï¼Œè‹¹æœçš„ï¼Œï¼‰ï¼ˆGPUImageï¼‰â€”â€”ã€‹æ˜¾ç¤ºï¼ˆå®é™…éƒ½æ˜¯å¯¹æ¯ä¸€ä¸ªç‚¹çš„å¤„ç†ï¼‰
 - (void)captureOutput:(AVCaptureOutput *)captureOutput didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection
 {//æ­¤æ–¹æ³•åœ¨å­çº¿ç¨‹æ— æ³•æ›´æ–°UI
 //    NSLog(@"è·å–ä¸€å¸§çš„æ•°æ®");
 //åˆ¤æ–­éŸ³é¢‘è¿˜æ˜¯è§†é¢‘
 
 
 //AVCaptureVideoPreViewLayer:å±•ç¤ºé‡‡é›†é¡µé¢
 //sampleBuffer:ä¸€å¸§æ•°æ®
 //sampleBuffer->UIImage
 //CoreImage:å¤„ç†åº•å±‚å›¾ç‰‡
 if(_AVoutput == captureOutput )
 {
 //        [self dealVideoData:sampleBuffer];
 [self prosesssampleBuffer:sampleBuffer];
 }else
 {
 //            NSLog(@"è·å–éŸ³é¢‘æ•°æ®çš„æ•°æ®");
 }
 }
 
 
 //ä¸¢å¸§ä»£ç†
 - (void)captureOutput:(AVCaptureOutput *)captureOutput didDropSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection NS_AVAILABLE(10_7, 6_0)
 {
 
 }
 
 */
/**************ä»£ç†æ–¹æ³•ä¸€äº›å°å¤„ç†å’Œä¸€äº›å°ä¸œè¥¿(â€”â€”â€”â€”å›¾ç‰‡â€”â€”â€”â€”)**************************
 //å¤„ç†æ•°æ®
 //æ˜¾ç¤ºåŸç”Ÿå›¾ç‰‡
 -(void)dealVideoData:(CMSampleBufferRef)sampleBuffer
 {
 CVImageBufferRef imageRef = CMSampleBufferGetImageBuffer(sampleBuffer);
 
 
 CIImage *img = [CIImage imageWithCVImageBuffer:imageRef];
 
 UIImage *iage =  [UIImage imageWithCIImage:img];
 dispatch_async(dispatch_get_main_queue(), ^{
 self.imageView.image = iage;
 });
 
 
 }
 */


/***********************å¤„ç†å›¾ç‰‡æ˜¾ç¤ºä¸€äº›å°ä¸œè¥¿ï¼ˆUIImageViewæœ‰å…³ï¼‰***************************
 
 
 -(UIImageView *)imageView
 {
 if(_imageView == nil)
 {//åº•å±‚æ‹¿åˆ°æ˜¯åçš„
 UIImageView *ima = [[UIImageView alloc] initWithFrame:self.view.bounds];
 
 
 
 ////        è®¾ç½®é”šç‚¹ è‡ªå·±æ
 //        ima.transform = CGAffineTransformMakeRotation(M_PI_2);
 //        UIImageView *ima = [[UIImageView alloc] initWithFrame:CGRectMake(0, 0, self.view.bounds.size.height, self.view.bounds.size.width)];
 //        ima.layer.anchorPoint = CGPointMake(0, 0);
 //        ima.layer.position = CGPointMake(self.view.bounds.size.width,0);
 [self.view addSubview:ima];
 _imageView = ima;
 }
 return _imageView;
 }
 
 */


/*****************************å·²ç»å°è£…è¿›å…¥ç›¸æœº*******************************
 Do any additional setup after loading the view, typically from a nib.
 åˆ›å»ºæ•æ‰ç»˜ç”»
 AVCaptureSession *session = [[AVCaptureSession alloc] init];
 å›¾ç‰‡å°ºå¯¸å¤§å°
 session.sessionPreset = AVCaptureSessionPreset1280x720;
 _session  = session;
 å¼€å§‹æ•è·æ•°æ®
 [_session startRunning];
 æŠŠæ•è·çš„æ•°æ®å±•ç¤ºåœ¨å±å¹•ä¸Š
 //é¢„è§ˆ
 AVCaptureVideoPreviewLayer *av =[AVCaptureVideoPreviewLayer layerWithSession:_session];
 //    av.automaticallyAdjustsMirroring è°ƒèŠ‚é•œåƒï¼ˆé»˜è®¤è‡ªåŠ¨è°ƒèŠ‚ï¼‰AVCaptureVideoOrientationæ‘„åƒå¤´æ–¹å‘
 
 av.frame = self.view.bounds;
 [self.view.layer addSublayer:av];
 */

